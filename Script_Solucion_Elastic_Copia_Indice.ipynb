{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install elasticsearch"
      ],
      "metadata": {
        "id": "t-THT7qJhIeB",
        "outputId": "23d277cd-200e-4615-f244-c407c0b263cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.5.2-py3-none-any.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2022.9.24)\n",
            "Collecting urllib3<2,>=1.26.2\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 49.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, elastic-transport, elasticsearch\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed elastic-transport-8.4.0 elasticsearch-8.5.2 urllib3-1.26.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulos"
      ],
      "metadata": {
        "id": "6HoKPTwbqc9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importacion de modulos \n",
        "import elasticsearch\n",
        "import numpy as np\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch import client\n",
        "from datetime import datetime\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "pmSEOpC83tFy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inputs "
      ],
      "metadata": {
        "id": "2t3qWrTlqine"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Informacion sobre la incidencia\n",
        "fecha_inicio_incidencia = \"2022-03-04 23:50:00\" # Meter la hora según timezone\n",
        "fecha_fin_incidencia    = \"2022-03-06 00:10:00\" # Meter la hora según timezone\n",
        "\n",
        "# Nombre del Job de Elastic\n",
        "jobname                 = \"sabado_anomalia\""
      ],
      "metadata": {
        "id": "Q894CsyMYQ9I"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de la conexion con el servidor de Elastic\n",
        "ELASTIC_PASSWORD = \"9QJVpAsI1dfU33vZpc072VTd\"\n",
        "CLOUD_ID = \"SeriestemporalesElastic:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQxMmRiODkwZjhhN2U0YTVjOTAwMDViODMyZjhlYWViNCRjMmU4YmQxYjkzZTI0MGY5OTZiYzIyNTFkZGMxMGY4Yg==\"\n",
        "\n",
        "client = Elasticsearch(\n",
        "    cloud_id=CLOUD_ID,\n",
        "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
        ")"
      ],
      "metadata": {
        "id": "hDOLpStE4DlO"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuevas Variables"
      ],
      "metadata": {
        "id": "sGR3NnT_qn23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculo del offset por cambio de hora\n",
        "\n",
        "# Timestamps fechas incidencia\n",
        "fecha_inicio_incidencia = datetime.strptime(fecha_inicio_incidencia, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_inicio_incidencia_timestamp = datetime.timestamp(fecha_inicio_incidencia)*1000\n",
        "\n",
        "fecha_fin_incidencia = datetime.strptime(fecha_fin_incidencia, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_fin_incidencia_timestamp = datetime.timestamp(fecha_fin_incidencia)*1000\n",
        "\n",
        "# Timestamps de las fechas de cambio de hora\n",
        "\n",
        "# Primer cambio de hora\n",
        "fecha_cambio_hora_1 = \"2022-03-27 02:00:00\" \n",
        "fecha_cambio_hora_1 = datetime.strptime(fecha_cambio_hora_1, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_cambio_hora_1_timestamp = datetime.timestamp(fecha_cambio_hora_1)*1000\n",
        "\n",
        "# Segundo cambio de hora\n",
        "fecha_cambio_hora_2 = \"2022-10-30 02:00:00\" \n",
        "fecha_cambio_hora_2 = datetime.strptime(fecha_cambio_hora_2, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_cambio_hora_2_timestamp = datetime.timestamp(fecha_cambio_hora_2)*1000\n",
        "\n",
        "# Comparamos fechas en el mismo año \n",
        "fecha_inicio_incidencia_cambio_timestamp = (datetime(2022, fecha_inicio_incidencia.month, fecha_inicio_incidencia.day, fecha_inicio_incidencia.hour, fecha_inicio_incidencia.minute, fecha_inicio_incidencia.second).timestamp())*1000 \n",
        "\n",
        "if (fecha_inicio_incidencia_cambio_timestamp < fecha_cambio_hora_1_timestamp):\n",
        "    offset_1 = -3600 \n",
        "\n",
        "elif ((fecha_inicio_incidencia_cambio_timestamp > fecha_cambio_hora_1_timestamp) and (fecha_inicio_incidencia_cambio_timestamp < fecha_cambio_hora_2_timestamp)):\n",
        "  offset_1 = -7200\n",
        "\n",
        "else (fecha_cambio_hora_2_timestamp < fecha_inicio_incidencia_cambio_timestamp):\n",
        "  offset_1 = -3600  \n",
        "\n",
        "fecha_fin_incidencia_cambio_timestamp = (datetime(2022, fecha_fin_incidencia.month, fecha_fin_incidencia.day, fecha_fin_incidencia.hour, fecha_fin_incidencia.minute, fecha_fin_incidencia.second).timestamp())*1000 \n",
        "\n",
        "if (fecha_fin_incidencia_cambio_timestamp < fecha_cambio_hora_1_timestamp):\n",
        "    offset_2 = -3600 \n",
        "\n",
        "elif ((fecha_fin_incidencia_cambio_timestamp > fecha_cambio_hora_1_timestamp) and (fecha_fin_incidencia_cambio_timestamp < fecha_cambio_hora_2_timestamp)):\n",
        "  offset_2 = -7200\n",
        "\n",
        "else (fecha_cambio_hora_2_timestamp < fecha_fin_incidencia_cambio_timestamp):\n",
        "  offset_2 = -3600  "
      ],
      "metadata": {
        "id": "KZU76-vHbx6X"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformacion de variables de entrada\n",
        "# Fechas\n",
        "fecha_inicio_incidencia = str((int(fecha_inicio_incidencia_timestamp + offset_1*1000)))\n",
        "fecha_fin_incidencia = str((int(fecha_fin_incidencia_timestamp + offset_2*1000)))\n",
        "\n",
        "# Nombre del Datafeed\n",
        "datafeed_id = \"datafeed-\" + jobname\n",
        "\n",
        "# Cliente de ML\n",
        "cliente_ml = client.ml"
      ],
      "metadata": {
        "id": "LKA4KL7_6Xle"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solución"
      ],
      "metadata": {
        "id": "KHmFmwh2qs2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1. Parar y cerrar el Job\n",
        "cliente_ml.close_job(job_id=jobname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AhE18gCeT3s",
        "outputId": "819a44d9-4334-431e-b50d-fb07898c5ed4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'closed': True})"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2. Escoger el id de la snapshot con latest_record_time_stamp mas cercano a la incidencia\n",
        "snapshots_available = cliente_ml.get_model_snapshots(job_id=jobname)\n",
        "# Recoger el count \n",
        "number_snapshots = snapshots_available[\"count\"]\n",
        "# Iterar guardando en una matriz el id del snpashot y latest_record_time_stamp\n",
        "snapshots_info = snapshots_available[\"model_snapshots\"]\n",
        "latest = np.zeros((number_snapshots, 2))\n",
        "for i in range(number_snapshots):\n",
        "  latest[i,0] = snapshots_info[i][\"latest_record_time_stamp\"]\n",
        "\n",
        "for i in range(number_snapshots):\n",
        "  latest[i,1] = snapshots_info[i][\"snapshot_id\"]\n",
        "\n",
        "# Comparar con la fecha de la incidencia para buscar cual esta inmediatamente antes\n",
        "  # Ordenar por timestamp (primera columna)\n",
        "  latest1 = latest[latest[:,0].argsort()]\n",
        "  latest2 = np.flip(latest1, axis=0)\n",
        "  # Eliminar valores mayores\n",
        "  latest3 = latest2[latest2[:,0]<float(fecha_inicio_incidencia)]\n",
        "# Escoger el id de la reversion correcta\n",
        "id_revert = latest3[0,1]\n",
        "id_revert = str(int(id_revert))"
      ],
      "metadata": {
        "id": "MrC1uVf-Pqz3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "0f546502-ce8c-4173-ba04-40e68a2fedde"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-07284dc6d107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mlatest2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Eliminar valores mayores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mlatest3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatest2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfecha_inicio_incidencia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# Escoger el id de la reversion correcta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mid_revert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'datetime.datetime'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3. Revertir el Job antes de la incidencia \n",
        "cliente_ml.revert_model_snapshot(job_id=jobname, snapshot_id=id_revert, delete_intervening_results=True)\n",
        "sleep(5)"
      ],
      "metadata": {
        "id": "Gqc32uAMeZ40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4. Abrir el Job \n",
        "cliente_ml.open_job(job_id=jobname)\n",
        "sleep(5)"
      ],
      "metadata": {
        "id": "LKuk9FApej7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5. Avanzamos datafeed hasta la fecha de inicio de incidencia\n",
        "cliente_ml.start_datafeed(datafeed_id=datafeed_id, end=fecha_inicio_incidencia)\n",
        "state_datafeed = 1\n",
        "\n",
        "# Una vez completado el paso continuamos al siguiente\n",
        "while (state_datafeed == 1):\n",
        "  sleep(10)\n",
        "  state_datafd = cliente_ml.get_datafeed_stats(datafeed_id=datafeed_id)\n",
        "  st = state_datafd['datafeeds']\n",
        "  state_actual = st[0]['state'] \n",
        "  if (state_actual == 'stopped'):\n",
        "    state_datafeed = 0"
      ],
      "metadata": {
        "id": "LMIo4Uw7es2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6. Abrir el Job \n",
        "cliente_ml.open_job(job_id=jobname)\n",
        "sleep(5)"
      ],
      "metadata": {
        "id": "cS4jQ-gqt3hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 7. Avanzamos datafeed desde la fecha de fin de incidencia hasta la fecha actual\n",
        "cliente_ml.start_datafeed(datafeed_id=datafeed_id, start=fecha_fin_incidencia)"
      ],
      "metadata": {
        "id": "aI8tSEvyet-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte de Indices"
      ],
      "metadata": {
        "id": "ApNixb3H0-qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install eland\n",
        "#!pip install elasticsearch"
      ],
      "metadata": {
        "id": "cEktGNiU-yQe"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importacion de modulos \n",
        "import elasticsearch\n",
        "import numpy as np\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch import client\n",
        "from datetime import datetime\n",
        "from time import sleep\n",
        "from elasticsearch.client import IndicesClient\n",
        "import eland as ed\n",
        "import pandas as pd\n",
        "from elasticsearch.client import IngestClient"
      ],
      "metadata": {
        "id": "zye1jStu1AQq"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inputs"
      ],
      "metadata": {
        "id": "21GAIsji3_pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Informacion sobre la incidencia\n",
        "fecha_inicio_incidencia = \"2022-03-04 23:50:00\" # Meter la hora segun timezone, no en UTC\n",
        "fecha_fin_incidencia    = \"2022-03-06 00:10:00\" # Meter la hora según timezone, no en UTC\n",
        "\n",
        "# Nombre del Job de Elastic\n",
        "jobname                 = \"sabado_anomalia\"\n",
        "variable_name_predict   = \"y_an\"\n",
        "\n",
        "# Nombre del indice sobre el que se realiza el Job\n",
        "index_data              = 'sabado_anomalia'"
      ],
      "metadata": {
        "id": "XGAOWWfn4BQd"
      },
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuevas variables"
      ],
      "metadata": {
        "id": "5n62EqUJKiXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculo del offset por cambio de hora\n",
        "\n",
        "# Timestamps fechas incidencia\n",
        "fecha_inicio_incidencia = datetime.strptime(fecha_inicio_incidencia, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_inicio_incidencia_timestamp = datetime.timestamp(fecha_inicio_incidencia)*1000\n",
        "\n",
        "fecha_fin_incidencia = datetime.strptime(fecha_fin_incidencia, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_fin_incidencia_timestamp = datetime.timestamp(fecha_fin_incidencia)*1000\n",
        "\n",
        "# Timestamps de las fechas de cambio de hora\n",
        "\n",
        "# Primer cambio de hora\n",
        "fecha_cambio_hora_1 = \"2022-03-27 02:00:00\" \n",
        "fecha_cambio_hora_1 = datetime.strptime(fecha_cambio_hora_1, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_cambio_hora_1_timestamp = datetime.timestamp(fecha_cambio_hora_1)*1000\n",
        "\n",
        "# Segundo cambio de hora\n",
        "fecha_cambio_hora_2 = \"2022-10-30 02:00:00\" \n",
        "fecha_cambio_hora_2 = datetime.strptime(fecha_cambio_hora_2, '%Y-%m-%d %H:%M:%S')\n",
        "fecha_cambio_hora_2_timestamp = datetime.timestamp(fecha_cambio_hora_2)*1000\n",
        "\n",
        "# Comparamos fechas en el mismo año \n",
        "fecha_inicio_incidencia_cambio_timestamp = (datetime(2022, fecha_inicio_incidencia.month, fecha_inicio_incidencia.day, fecha_inicio_incidencia.hour, fecha_inicio_incidencia.minute, fecha_inicio_incidencia.second).timestamp())*1000 \n",
        "\n",
        "if (fecha_inicio_incidencia_cambio_timestamp < fecha_cambio_hora_1_timestamp):\n",
        "    offset_1 = -3600 \n",
        "\n",
        "if ((fecha_inicio_incidencia_cambio_timestamp > fecha_cambio_hora_1_timestamp) and (fecha_inicio_incidencia_cambio_timestamp < fecha_cambio_hora_2_timestamp)):\n",
        "  offset_1 = -7200\n",
        "\n",
        "if (fecha_cambio_hora_2_timestamp < fecha_inicio_incidencia_cambio_timestamp):\n",
        "  offset_1 = -3600  \n",
        "\n",
        "fecha_fin_incidencia_cambio_timestamp = (datetime(2022, fecha_fin_incidencia.month, fecha_fin_incidencia.day, fecha_fin_incidencia.hour, fecha_fin_incidencia.minute, fecha_fin_incidencia.second).timestamp())*1000 \n",
        "\n",
        "if (fecha_fin_incidencia_cambio_timestamp < fecha_cambio_hora_1_timestamp):\n",
        "    offset_2 = -3600 \n",
        "\n",
        "if ((fecha_fin_incidencia_cambio_timestamp > fecha_cambio_hora_1_timestamp) and (fecha_fin_incidencia_cambio_timestamp < fecha_cambio_hora_2_timestamp)):\n",
        "  offset_2 = -7200\n",
        "\n",
        "if (fecha_cambio_hora_2_timestamp < fecha_fin_incidencia_cambio_timestamp):\n",
        "  offset_2 = -3600  "
      ],
      "metadata": {
        "id": "sMl1DrpJKkdc"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformacion de variables de entrada\n",
        "# Fechas\n",
        "fecha_inicio_incidencia = (fecha_inicio_incidencia_timestamp + offset_1*1000)/1000\n",
        "fecha_inicio_incidencia_snapshot = fecha_inicio_incidencia*1000\n",
        "fecha_fin_incidencia    = (fecha_fin_incidencia_timestamp + offset_2*1000)/1000\n",
        "fecha_fin_incidencia_snapshot = fecha_fin_incidencia*1000\n",
        "# Avanzamos esta ultima fecha 2 hora \n",
        "fecha_fin_incidencia_snapshot_avanc = str((fecha_fin_incidencia+7200)*1000)\n",
        "\n",
        "fecha_inicio_incidencia_datetime = datetime.fromtimestamp(fecha_inicio_incidencia)\n",
        "fecha_fin_incidencia_datetime = datetime.fromtimestamp(fecha_fin_incidencia)\n",
        "\n",
        "fecha_inicio_incidencia_datetime_str = str(fecha_inicio_incidencia_datetime)\n",
        "fecha_fin_incidencia_datetime_str = str(fecha_fin_incidencia_datetime)\n",
        "fecha_inicio_incidencia_datetime_querie = fecha_inicio_incidencia_datetime_str[0:10] + 'T' + fecha_inicio_incidencia_datetime_str[11:]\n",
        "fecha_fin_incidencia_datetime_querie    = fecha_fin_incidencia_datetime_str[0:10] + 'T' + fecha_fin_incidencia_datetime_str[11:] \n",
        "\n",
        "# Nombre del Datafeed\n",
        "datafeed_id = \"datafeed-\" + jobname"
      ],
      "metadata": {
        "id": "XJClAMIsKulK"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de la conexion con el servidor de Elastic\n",
        "ELASTIC_PASSWORD = \"9QJVpAsI1dfU33vZpc072VTd\"\n",
        "CLOUD_ID = \"SeriestemporalesElastic:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQxMmRiODkwZjhhN2U0YTVjOTAwMDViODMyZjhlYWViNCRjMmU4YmQxYjkzZTI0MGY5OTZiYzIyNTFkZGMxMGY4Yg==\"\n",
        "\n",
        "es_client = Elasticsearch(\n",
        "    cloud_id=CLOUD_ID,\n",
        "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
        ")\n",
        "cliente_index = IndicesClient(client=es_client)"
      ],
      "metadata": {
        "id": "y8yeQ6qA1FFA"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solución"
      ],
      "metadata": {
        "id": "0D3wMDvCbFBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creacion del Indice de Backup\n",
        "indexname = 'indicebackup'\n",
        "indexname_2 = 'indicebackup2'\n",
        "indexname_3 = \"indicebackup3\"\n",
        "\n",
        "try:\n",
        "  cliente_index.create(index=indexname)\n",
        "except:\n",
        "  cliente_index.delete(index=indexname)\n",
        "  cliente_index.create(index=indexname)\n",
        "\n",
        "try:\n",
        "  cliente_index.create(index=indexname_2)\n",
        "except:\n",
        "  cliente_index.delete(index=indexname_2)\n",
        "  cliente_index.create(index=indexname_2)\n",
        "\n",
        "try:\n",
        "  cliente_index.create(index=indexname_3)\n",
        "except:\n",
        "  cliente_index.delete(index=indexname_3)\n",
        "  cliente_index.create(index=indexname_3)"
      ],
      "metadata": {
        "id": "IF2xwwwC1WGI"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reindexar datos de la anomalia al indice backup \n",
        "es_client.reindex(body={\n",
        "      \"source\": {\n",
        "          \"index\": index_data,\n",
        "          \"query\": {\n",
        "              \"range\":{\n",
        "                  \"@timestamp\":{\n",
        "                      \"gte\": fecha_inicio_incidencia_datetime_querie,\n",
        "                      \"lte\": fecha_fin_incidencia_datetime_querie\n",
        "                      }\n",
        "                   }\n",
        "                }\n",
        "              },\n",
        "              \"dest\": {\n",
        "                  \"index\": indexname\n",
        "              }})"
      ],
      "metadata": {
        "id": "F3CUSHqx4stO",
        "outputId": "e77f367d-17f5-4d45-c28c-88c1440691a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'took': 40, 'timed_out': False, 'total': 147, 'updated': 0, 'created': 147, 'deleted': 0, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener datos de la prediccion del Job para el tiempo de anomalia\n",
        "df = ed.DataFrame(es_client, es_index_pattern=\".ml-anomalies-shared\")\n",
        "# Filtramos para nuestro job de interes\n",
        "df = df[df[\"job_id\"] == jobname]\n",
        "# Obtenemos las columnas de interes del dataframe\n",
        "df_select = df[[\"timestamp\", \"model_median\", \"model_upper\"]]\n",
        "# Eliminar filas con valores nulos\n",
        "df_select = ed.eland_to_pandas(df_select)\n",
        "df_select = df_select.dropna()\n",
        "df_select.head(20)\n",
        "# Ordenamos filas por timestamp\n",
        "df_select.timestamp\n",
        "# Seleccionamos timestamp de interes\n",
        "df_select['timestamp'] = pd.to_datetime(df_select.timestamp)\n",
        "df_select_order = df_select.sort_values(by=\"timestamp\", ascending=True)\n",
        "df_select_order = df_select_order.set_index(\"timestamp\")\n",
        "df_select_filter = df_select_order.loc[fecha_inicio_incidencia_datetime:fecha_fin_incidencia_datetime]"
      ],
      "metadata": {
        "id": "cn5Zl2a81iBm"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer un rename del nombre de columna \"model_median\" al nombre de la variable que se predice en el JOB\n",
        "df_select_filter.rename(columns = {'model_median':variable_name_predict}, inplace = True)\n",
        "\n",
        "# Eliminar variable upper_name\n",
        "df_select_filter = df_select_filter.drop('model_upper', axis=1)\n",
        "df_select_filter = df_select_filter.reset_index()"
      ],
      "metadata": {
        "id": "2kVsPAJYNCtu",
        "outputId": "caceb2b3-350a-48cf-eff6-e372a5c39120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la pipeline de ingesta para @timestamp \n",
        "client_Ingest = IngestClient(client=es_client)\n",
        "\n",
        "try:\n",
        "  client_Ingest.put_pipeline(id='procesador_date_anomalias', body={\n",
        "      'description': \"Parsea el @timestamp\",\n",
        "      'processors': [\n",
        "          {\n",
        "              \"date\": {\n",
        "                  \"field\": \"timestamp\", \n",
        "                  \"formats\": [\"ISO8601\"],\n",
        "                  \"target_field\": \"@timestamp\"\n",
        "                  }\n",
        "          }\n",
        "          ]})\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# Introducir datos a un indice intermedio\n",
        "df_select_filter\n",
        "for i, row in df_select_filter.iterrows():\n",
        "    doc = {\n",
        "        \"timestamp\": row[\"timestamp\"],\n",
        "        \"y_an\": row[\"y_an\"]\n",
        "    }\n",
        "    es_client.index(index=indexname_2, id=i, document=doc)\n",
        "\n",
        "# Eliminar del indice principal datos para el timestamp de la incidencia\n",
        "es_client.delete_by_query(index=index_data, body={\n",
        "  \"query\": {\n",
        "    \"range\":{\n",
        "         \"@timestamp\":{\n",
        "            \"gte\": fecha_inicio_incidencia_datetime_querie,\n",
        "            \"lte\": fecha_fin_incidencia_datetime_querie\n",
        "          }\n",
        "        }\n",
        "  }\n",
        "})\n",
        "sleep(5)\n",
        "# Parsear a un indice los datos teniendo cuidado con el timestamp al indice principal\n",
        "es_client.reindex(body={\n",
        "      'source': {\n",
        "          \"index\": indexname_2\n",
        "          },\n",
        "          'dest': {\n",
        "              \"index\": index_data,\n",
        "              \"pipeline\": \"procesador_date_anomalias\"\n",
        "              }},\n",
        "              wait_for_completion=True)\n",
        "sleep(5)\n",
        "# Parsear a un indice los datos teniendo cuidado con el timestamp al indice principal\n",
        "es_client.reindex(body={\n",
        "      'source': {\n",
        "          \"index\": indexname_2\n",
        "          },\n",
        "          'dest': {\n",
        "              \"index\": index_data,\n",
        "              \"pipeline\": \"procesador_date_anomalias\"\n",
        "              }},\n",
        "              wait_for_completion=True)"
      ],
      "metadata": {
        "id": "HLMIl7ipQXkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b93263-c2d6-439d-f3ca-4f81b5ea7328"
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'took': 15, 'timed_out': False, 'total': 147, 'updated': 147, 'created': 0, 'deleted': 0, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []})"
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetear Job desde la snapshot (buscar snapshot como en el modelo anterior y correr job)\n",
        "# Paso 1. Parar y cerrar el Job\n",
        "cliente_ml.close_job(job_id=jobname)\n",
        "# Paso 2. Escoger el id de la snapshot con latest_record_time_stamp mas cercano a la incidencia\n",
        "snapshots_available = cliente_ml.get_model_snapshots(job_id=jobname)\n",
        "# Recoger el count \n",
        "number_snapshots = snapshots_available[\"count\"]\n",
        "# Iterar guardando en una matriz el id del snpashot y latest_record_time_stamp\n",
        "snapshots_info = snapshots_available[\"model_snapshots\"]\n",
        "latest = np.zeros((number_snapshots, 2))\n",
        "for i in range(number_snapshots):\n",
        "  latest[i,0] = snapshots_info[i][\"latest_record_time_stamp\"]\n",
        "\n",
        "for i in range(number_snapshots):\n",
        "  latest[i,1] = snapshots_info[i][\"snapshot_id\"]\n",
        "\n",
        "# Comparar con la fecha de la incidencia para buscar cual esta inmediatamente antes\n",
        "  # Ordenar por timestamp (primera columna)\n",
        "  latest1 = latest[latest[:,0].argsort()]\n",
        "  latest2 = np.flip(latest1, axis=0)\n",
        "  # Eliminar valores mayores\n",
        "  latest3 = latest2[latest2[:,0]<float(fecha_inicio_incidencia_snapshot)]\n",
        "# Escoger el id de la reversion correcta\n",
        "id_revert = latest3[0,1]\n",
        "id_revert = str(int(id_revert))\n",
        "# Paso 3. Revertir el Job antes de la incidencia \n",
        "cliente_ml.revert_model_snapshot(job_id=jobname, snapshot_id=id_revert, delete_intervening_results=True)\n",
        "# Paso 4. Abrir el Job \n",
        "cliente_ml.open_job(job_id=jobname)\n",
        "# Paso 5. Avanzamos datafeed hasta la fecha de inicio de incidencia\n",
        "cliente_ml.start_datafeed(datafeed_id=datafeed_id, end=str(fecha_fin_incidencia_snapshot))\n",
        "state_datafeed = 1\n",
        "\n",
        "# Una vez completado el paso continuamos al siguiente\n",
        "while (state_datafeed == 1):\n",
        "  sleep(10)\n",
        "  state_datafd = cliente_ml.get_datafeed_stats(datafeed_id=datafeed_id)\n",
        "  st = state_datafd['datafeeds']\n",
        "  state_actual = st[0]['state'] \n",
        "  if (state_actual == 'stopped'):\n",
        "    state_datafeed = 0"
      ],
      "metadata": {
        "id": "GTpszXekQqrT"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Borrado de Indices"
      ],
      "metadata": {
        "id": "WxHi9XAa0J6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sustituir datos del indice backup al indice original para el tiempo de incidencia\n",
        "# 1. Eliminar datos ingestados de la prediccion para el tiempo de incidencia\n",
        "es_client.delete_by_query(index=index_data, body={\n",
        "  \"query\": {\n",
        "    \"range\":{\n",
        "         \"@timestamp\":{\n",
        "            \"gte\": fecha_inicio_incidencia_datetime_querie,\n",
        "            \"lte\": fecha_fin_incidencia_datetime_querie\n",
        "          }\n",
        "        }\n",
        "  }\n",
        "})\n",
        "sleep(5)\n",
        "# 2. Ingesta de los datos del backup para el tiempo de incidencia\n",
        "es_client.reindex(body={\n",
        "      \"source\": {\n",
        "          \"index\": indexname,\n",
        "          \"query\": {\n",
        "              \"range\":{\n",
        "                  \"@timestamp\":{\n",
        "                      \"gte\": fecha_inicio_incidencia_datetime_querie,\n",
        "                      \"lte\": fecha_fin_incidencia_datetime_querie\n",
        "                      }\n",
        "                   }\n",
        "                }\n",
        "              },\n",
        "              \"dest\": {\n",
        "                  \"index\": index_data\n",
        "              }},\n",
        "              wait_for_completion=True)\n",
        "sleep(5)"
      ],
      "metadata": {
        "id": "KxE8-WQiQyAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004aed01-23c7-421e-e275-2269f166f4cc"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar indices creados\n",
        "try:\n",
        "  cliente_index.delete(index=indexname)\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  cliente_index.delete(index=indexname_2)\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  cliente_index.delete(index=indexname_3)\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "BiPOcXEcrYYO"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6. Avanzamos datafeed hasta el tiempo real\n",
        "cliente_ml.open_job(job_id=jobname)\n",
        "sleep(5)\n",
        "cliente_ml.start_datafeed(datafeed_id=datafeed_id, start=str(fecha_fin_incidencia_snapshot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PilECtHYFBKN",
        "outputId": "3168146e-d9ae-41e1-bf8d-5a21e7c65e9c"
      },
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'started': True, 'node': 'CxrRZr0BSsmLbYiv4E042Q'})"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
